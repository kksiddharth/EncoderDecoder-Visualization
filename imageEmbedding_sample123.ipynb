{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imageEmbedding_sample123.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kksiddharth/sample/blob/master/imageEmbedding_sample123.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gWXEHYbtjDOW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tensorflow.layers import flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCQ_wiN3kXdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6D2wpLX7jG9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilxZKeJsjI6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ce122b6-631d-4e75-ab37-d84941ebcaad"
      },
      "cell_type": "code",
      "source": [
        "PATH"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "IYyNeNTDjLCX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir_list = os.listdir(PATH)\n",
        "path = []\n",
        "for i in data_dir_list:\n",
        "    if 'jpg' in i:\n",
        "        path.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wgsEjuCjM9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d16b3184-0f64-417d-c6c4-580693c12ce7"
      },
      "cell_type": "code",
      "source": [
        "len(path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Myt7FsBDjOh4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Data_Set_Creator():\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.dir_list = path\n",
        "        self.img_rows = 60\n",
        "        self.img_cols = 60\n",
        "        self.num_channel = 3\n",
        "        self.num_epoch = 10\n",
        "        \n",
        "#        self.num_classes = 4\n",
        "        self.i = 0\n",
        "        \n",
        "        self.img_data_list=[]\n",
        "#        self.labels_list = []\n",
        "        self.img_data = []\n",
        "#        self.labels_name={'amazon':0,'ichiba':1,'rakuten':2,'alibaba':3}\n",
        "        \n",
        "    \n",
        "    def set_up_data(self):\n",
        "        print('Setting up Data')\n",
        "        for img in self.dir_list:\n",
        "            img=cv2.imread(data_path + img)\n",
        "            input_img_resize=cv2.resize(img,(self.img_rows,self.img_cols))\n",
        "            self.img_data_list.append(input_img_resize)\n",
        "                \n",
        "        self.img_data = np.array(self.img_data_list)\n",
        "        self.img_data = self.img_data.astype('float32')\n",
        "        self.img_data /= 255\n",
        "        \n",
        "        x = shuffle(self.img_data, random_state=2)\n",
        "        return x\n",
        "\n",
        "    \n",
        "    def next_batch(self, x_train,batch_size):\n",
        "        x = x_train[self.i:self.i+batch_size].reshape(batch_size,self.img_rows,self.img_cols,self.num_channel)\n",
        "        self.i = (self.i + batch_size) % len(x_train)\n",
        "        return x\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDuZjFjNjZl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fa7fc5a-369f-4e09-d543-a71e3899cc02"
      },
      "cell_type": "code",
      "source": [
        "obj = Data_Set_Creator()\n",
        "x = obj.set_up_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting up Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RxyhINlpjcCT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_weights(shape):\n",
        "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(init_random_dist)\n",
        "\n",
        "def init_bias(shape):\n",
        "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(init_bias_vals)\n",
        "\n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2by2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "def convolutional_layer(input_x, shape):\n",
        "    W = init_weights(shape)\n",
        "    b = init_bias([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
        "\n",
        "def normal_full_layer(input_layer, size):\n",
        "    input_size = int(input_layer.get_shape()[1])\n",
        "    W = init_weights([input_size, size])\n",
        "    b = init_bias([size])\n",
        "    return tf.matmul(input_layer, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BMdRKf_DjfHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(x, test_size=0.1, random_state=2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBsP3HfvjmJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a7a9d5c1-3dce-429d-84bc-2008c4c134f3"
      },
      "cell_type": "code",
      "source": [
        "initializer = tf.variance_scaling_initializer()\n",
        "\n",
        "x = tf.placeholder(tf.float32,shape=[None,obj.img_rows,obj.img_cols,obj.num_channel])\n",
        "\n",
        "convo_1 = convolutional_layer(x,shape=[4,4,3,32])\n",
        "convo_1_pooling = max_pool_2by2(convo_1)\n",
        "\n",
        "convo_2 = convolutional_layer(convo_1_pooling,shape=[4,4,32,64])\n",
        "convo_2_pooling = max_pool_2by2(convo_2)\n",
        "\n",
        "a = flatten(convo_2_pooling)\n",
        "\n",
        "num_inputs = 14400\n",
        "neurons_hid1 = 4096\n",
        "neurons_hid2 = 1024\n",
        "neurons_hid3 = 256\n",
        "neurons_hid4 = neurons_hid2\n",
        "neurons_hid5 = neurons_hid1 # Decoder Begins\n",
        "num_outputs = num_inputs\n",
        "\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-6ae2d17cdab3>:11: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lNk65QcHjrTh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w1 = tf.Variable(initializer([num_inputs, neurons_hid1]), dtype=tf.float32)\n",
        "w2 = tf.Variable(initializer([neurons_hid1, neurons_hid2]), dtype=tf.float32)\n",
        "w3 = tf.Variable(initializer([neurons_hid2, neurons_hid3]), dtype=tf.float32)\n",
        "w4 = tf.Variable(initializer([neurons_hid3, neurons_hid4]), dtype=tf.float32)\n",
        "w5 = tf.Variable(initializer([neurons_hid4, neurons_hid5]), dtype=tf.float32)\n",
        "w6 = tf.Variable(initializer([neurons_hid5, num_outputs]), dtype=tf.float32)\n",
        "\n",
        "b1 = tf.Variable(tf.zeros(neurons_hid1))\n",
        "b2 = tf.Variable(tf.zeros(neurons_hid2))\n",
        "b3 = tf.Variable(tf.zeros(neurons_hid3))\n",
        "b4 = tf.Variable(tf.zeros(neurons_hid4))\n",
        "b5 = tf.Variable(tf.zeros(neurons_hid5))\n",
        "b6 = tf.Variable(tf.zeros(num_outputs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fmpVmRRSj3oY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "act_func = tf.nn.relu\n",
        "\n",
        "hid_layer1 = act_func(tf.matmul(a, w1) + b1)\n",
        "hid_layer2 = act_func(tf.matmul(hid_layer1, w2) + b2)\n",
        "hid_layer3 = act_func(tf.matmul(hid_layer2, w3) + b3)\n",
        "hid_layer4 = act_func(tf.matmul(hid_layer3, w4) + b4)\n",
        "hid_layer5 = act_func(tf.matmul(hid_layer4, w5) + b5)\n",
        "output_layer = tf.matmul(hid_layer5, w6) + b6\n",
        "\n",
        "loss = tf.reduce_mean(tf.square(output_layer - a))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NBEvS0B8j6OJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "saver = tf.train.Saver() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_98U2uYj7t7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = obj.num_epoch\n",
        "#num_epochs = 10\n",
        "batch_size = 150\n",
        "num_samples = len(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eivZrV-6j9U9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    # Epoch == Entire Training Set\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        num_batches = num_samples // batch_size\n",
        "        \n",
        "        # 150 batch size\n",
        "        for iteration in range(num_batches):\n",
        "            try:\n",
        "                X_batch = obj.next_batch(X_train,150)\n",
        "            except:\n",
        "                X_batch = obj.next_batch(X_train,126)\n",
        "            sess.run(train, feed_dict={x: X_batch})\n",
        "            \n",
        "        training_loss = loss.eval(feed_dict={x: X_batch})   \n",
        "        \n",
        "        print(\"Epoch {} Complete. Training Loss: {}\".format(epoch,training_loss))\n",
        "     \n",
        "    saver.save(sess, \"./imageEmbedding_tet123.ckpt\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xYlxDmTj_y3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_test_images = 10\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver.restore(sess,\"./imageEmbedding_tet123.ckpt\")\n",
        "    \n",
        "    results = output_layer.eval(feed_dict={x:X_test[:num_test_images]})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}